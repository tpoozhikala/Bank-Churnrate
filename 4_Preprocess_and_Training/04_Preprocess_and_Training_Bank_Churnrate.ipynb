{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Bank_Churnrate_Preprocess_and_Training<a id='2_Data_wrangling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Table of Contents<a id='2.1_Contents'></a>\n",
    "* 4. Bank_Churnrate_Preprocess_and_Training\n",
    "  * 4.1 Table of Contents\n",
    "  * 4.2 Introduction\n",
    "  * 4.3 Imports\n",
    "  * 4.4 Load Bank Churn Missing and Dropped Datasets\n",
    "  * 4.5 Create Train_Test Split & Preprocess Training Data\n",
    "    * 4.5.1 Number & Handling Of Missing Values \n",
    "    * 4.5.2 Determing Correlation of Features with Target Feature (\"Attrition_Flag\")\n",
    "      * 4.5.2.1 Determine User Base Churn vs. Not Churned\n",
    "      * 4.5.2.2 One-Hot Encoding & Correlation with Categorical Features\n",
    "  * 4.6 Save Data\n",
    "  * 4.7 Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a thorough analysis as well as further cleaning and One-Hot enconding steps were implemented in prior EDA, train and test sets based on a usual 70/30 split will be created based on both the missing and dropped bank churn datasets for future steps in assessing model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Imports<a id='2.3_Imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all appropriate packages in order to develop associated train and test sets for both imputed and dropped datasets for bank churn rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas, matplotlib.pyplot, seaborn, and associated scikit learn methods and functions as well as random number for reproducibility\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "random_number = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Load Bank Churn Missing and Dropped Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading associated datasets of dropped vs. missing datasets for bank churn rate.\n",
    "path_missing = 'C:/Users/tpooz/OneDrive/Desktop/Data_Science_BootCamp_2023/SpringBoard_Github/Bank-Churnrate/0_Datasets/bank_data_train_preprocessed_missing.csv'\n",
    "path_dropped = 'C:/Users/tpooz/OneDrive/Desktop/Data_Science_BootCamp_2023/SpringBoard_Github/Bank-Churnrate/0_Datasets/bank_data_train_preprocessed_dropped.csv'\n",
    "bank_missing_df = pd.read_csv(path_missing, index_col=0)\n",
    "bank_dropped_df = pd.read_csv(path_dropped, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auditing the datasets with .info() and .head() displaying the first few records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8101 entries, 0 to 8100\n",
      "Data columns (total 38 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Customer_Age                    8101 non-null   int64  \n",
      " 1   Dependent_count                 8101 non-null   int64  \n",
      " 2   Months_on_book                  8101 non-null   int64  \n",
      " 3   Total_Relationship_Count        8101 non-null   int64  \n",
      " 4   Months_Inactive_12_mon          8101 non-null   int64  \n",
      " 5   Contacts_Count_12_mon           8101 non-null   int64  \n",
      " 6   Credit_Limit                    8101 non-null   float64\n",
      " 7   Total_Revolving_Bal             8101 non-null   int64  \n",
      " 8   Avg_Open_To_Buy                 8101 non-null   float64\n",
      " 9   Total_Amt_Chng_Q4_Q1            8101 non-null   float64\n",
      " 10  Total_Trans_Amt                 8101 non-null   int64  \n",
      " 11  Total_Trans_Ct                  8101 non-null   int64  \n",
      " 12  Total_Ct_Chng_Q4_Q1             8101 non-null   float64\n",
      " 13  Avg_Utilization_Ratio           8101 non-null   float64\n",
      " 14  Attrition_Flag                  8101 non-null   int64  \n",
      " 15  Gender_F                        8101 non-null   int64  \n",
      " 16  Gender_M                        8101 non-null   int64  \n",
      " 17  Education_Level_College         8101 non-null   int64  \n",
      " 18  Education_Level_Doctorate       8101 non-null   int64  \n",
      " 19  Education_Level_Graduate        8101 non-null   int64  \n",
      " 20  Education_Level_High School     8101 non-null   int64  \n",
      " 21  Education_Level_Post-Graduate   8101 non-null   int64  \n",
      " 22  Education_Level_Uneducated      8101 non-null   int64  \n",
      " 23  Education_Level_missing         8101 non-null   int64  \n",
      " 24  Marital_Status_Divorced         8101 non-null   int64  \n",
      " 25  Marital_Status_Married          8101 non-null   int64  \n",
      " 26  Marital_Status_Single           8101 non-null   int64  \n",
      " 27  Marital_Status_missing          8101 non-null   int64  \n",
      " 28  Income_Category_$120K +         8101 non-null   int64  \n",
      " 29  Income_Category_$40K - $60K     8101 non-null   int64  \n",
      " 30  Income_Category_$60K - $80K     8101 non-null   int64  \n",
      " 31  Income_Category_$80K - $120K    8101 non-null   int64  \n",
      " 32  Income_Category_Less than $40K  8101 non-null   int64  \n",
      " 33  Income_Category_missing         8101 non-null   int64  \n",
      " 34  Card_Category_Blue              8101 non-null   int64  \n",
      " 35  Card_Category_Gold              8101 non-null   int64  \n",
      " 36  Card_Category_Platinum          8101 non-null   int64  \n",
      " 37  Card_Category_Silver            8101 non-null   int64  \n",
      "dtypes: float64(5), int64(33)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "#.info() on bank_missing_df and bank_dropped_df to see a summary of the data\n",
    "bank_missing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5690 entries, 3 to 8100\n",
      "Data columns (total 35 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Customer_Age                    5690 non-null   int64  \n",
      " 1   Dependent_count                 5690 non-null   int64  \n",
      " 2   Months_on_book                  5690 non-null   int64  \n",
      " 3   Total_Relationship_Count        5690 non-null   int64  \n",
      " 4   Months_Inactive_12_mon          5690 non-null   int64  \n",
      " 5   Contacts_Count_12_mon           5690 non-null   int64  \n",
      " 6   Credit_Limit                    5690 non-null   float64\n",
      " 7   Total_Revolving_Bal             5690 non-null   int64  \n",
      " 8   Avg_Open_To_Buy                 5690 non-null   float64\n",
      " 9   Total_Amt_Chng_Q4_Q1            5690 non-null   float64\n",
      " 10  Total_Trans_Amt                 5690 non-null   int64  \n",
      " 11  Total_Trans_Ct                  5690 non-null   int64  \n",
      " 12  Total_Ct_Chng_Q4_Q1             5690 non-null   float64\n",
      " 13  Avg_Utilization_Ratio           5690 non-null   float64\n",
      " 14  Attrition_Flag                  5690 non-null   int64  \n",
      " 15  Gender_F                        5690 non-null   int64  \n",
      " 16  Gender_M                        5690 non-null   int64  \n",
      " 17  Education_Level_College         5690 non-null   int64  \n",
      " 18  Education_Level_Doctorate       5690 non-null   int64  \n",
      " 19  Education_Level_Graduate        5690 non-null   int64  \n",
      " 20  Education_Level_High School     5690 non-null   int64  \n",
      " 21  Education_Level_Post-Graduate   5690 non-null   int64  \n",
      " 22  Education_Level_Uneducated      5690 non-null   int64  \n",
      " 23  Marital_Status_Divorced         5690 non-null   int64  \n",
      " 24  Marital_Status_Married          5690 non-null   int64  \n",
      " 25  Marital_Status_Single           5690 non-null   int64  \n",
      " 26  Income_Category_$120K +         5690 non-null   int64  \n",
      " 27  Income_Category_$40K - $60K     5690 non-null   int64  \n",
      " 28  Income_Category_$60K - $80K     5690 non-null   int64  \n",
      " 29  Income_Category_$80K - $120K    5690 non-null   int64  \n",
      " 30  Income_Category_Less than $40K  5690 non-null   int64  \n",
      " 31  Card_Category_Blue              5690 non-null   int64  \n",
      " 32  Card_Category_Gold              5690 non-null   int64  \n",
      " 33  Card_Category_Platinum          5690 non-null   int64  \n",
      " 34  Card_Category_Silver            5690 non-null   int64  \n",
      "dtypes: float64(5), int64(30)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "bank_dropped_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>...</th>\n",
       "      <th>Income_Category_$120K +</th>\n",
       "      <th>Income_Category_$40K - $60K</th>\n",
       "      <th>Income_Category_$60K - $80K</th>\n",
       "      <th>Income_Category_$80K - $120K</th>\n",
       "      <th>Income_Category_Less than $40K</th>\n",
       "      <th>Income_Category_missing</th>\n",
       "      <th>Card_Category_Blue</th>\n",
       "      <th>Card_Category_Gold</th>\n",
       "      <th>Card_Category_Platinum</th>\n",
       "      <th>Card_Category_Silver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.595</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5396.0</td>\n",
       "      <td>1803</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15987.0</td>\n",
       "      <td>1648</td>\n",
       "      <td>14339.0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3625.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1.158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.602</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0            54                1              36                         1   \n",
       "1            58                4              48                         1   \n",
       "2            45                4              36                         6   \n",
       "3            34                2              36                         4   \n",
       "4            49                2              39                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                       3                      3        3723.0   \n",
       "1                       4                      3        5396.0   \n",
       "2                       1                      3       15987.0   \n",
       "3                       3                      4        3625.0   \n",
       "4                       3                      4        2720.0   \n",
       "\n",
       "   Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  ...  \\\n",
       "0                 1728           1995.0                 0.595  ...   \n",
       "1                 1803           3593.0                 0.493  ...   \n",
       "2                 1648          14339.0                 0.732  ...   \n",
       "3                 2517           1108.0                 1.158  ...   \n",
       "4                 1926            794.0                 0.602  ...   \n",
       "\n",
       "   Income_Category_$120K +  Income_Category_$40K - $60K  \\\n",
       "0                        0                            0   \n",
       "1                        0                            0   \n",
       "2                        0                            0   \n",
       "3                        0                            0   \n",
       "4                        0                            1   \n",
       "\n",
       "   Income_Category_$60K - $80K  Income_Category_$80K - $120K  \\\n",
       "0                            0                             0   \n",
       "1                            0                             0   \n",
       "2                            0                             0   \n",
       "3                            0                             0   \n",
       "4                            0                             0   \n",
       "\n",
       "   Income_Category_Less than $40K  Income_Category_missing  \\\n",
       "0                               0                        1   \n",
       "1                               0                        1   \n",
       "2                               1                        0   \n",
       "3                               1                        0   \n",
       "4                               0                        0   \n",
       "\n",
       "   Card_Category_Blue  Card_Category_Gold  Card_Category_Platinum  \\\n",
       "0                   1                   0                       0   \n",
       "1                   1                   0                       0   \n",
       "2                   0                   1                       0   \n",
       "3                   1                   0                       0   \n",
       "4                   1                   0                       0   \n",
       "\n",
       "   Card_Category_Silver  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#head method on bank_missing_df and bank_dropped_df to print the first several rows of the data\n",
    "bank_missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>...</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Income_Category_$120K +</th>\n",
       "      <th>Income_Category_$40K - $60K</th>\n",
       "      <th>Income_Category_$60K - $80K</th>\n",
       "      <th>Income_Category_$80K - $120K</th>\n",
       "      <th>Income_Category_Less than $40K</th>\n",
       "      <th>Card_Category_Blue</th>\n",
       "      <th>Card_Category_Gold</th>\n",
       "      <th>Card_Category_Platinum</th>\n",
       "      <th>Card_Category_Silver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3625.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1.158</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.602</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>648</td>\n",
       "      <td>790.3</td>\n",
       "      <td>0.477</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>1623</td>\n",
       "      <td>927.0</td>\n",
       "      <td>0.650</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>0.677</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "3            34                2              36                         4   \n",
       "4            49                2              39                         5   \n",
       "5            60                0              45                         5   \n",
       "8            30                0              36                         3   \n",
       "9            33                3              36                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "3                       3                      4        3625.0   \n",
       "4                       3                      4        2720.0   \n",
       "5                       2                      4        1438.3   \n",
       "8                       3                      2        2550.0   \n",
       "9                       2                      3        1457.0   \n",
       "\n",
       "   Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  ...  \\\n",
       "3                 2517           1108.0                 1.158  ...   \n",
       "4                 1926            794.0                 0.602  ...   \n",
       "5                  648            790.3                 0.477  ...   \n",
       "8                 1623            927.0                 0.650  ...   \n",
       "9                    0           1457.0                 0.677  ...   \n",
       "\n",
       "   Marital_Status_Single  Income_Category_$120K +  \\\n",
       "3                      1                        0   \n",
       "4                      0                        0   \n",
       "5                      0                        0   \n",
       "8                      0                        0   \n",
       "9                      1                        0   \n",
       "\n",
       "   Income_Category_$40K - $60K  Income_Category_$60K - $80K  \\\n",
       "3                            0                            0   \n",
       "4                            1                            0   \n",
       "5                            0                            0   \n",
       "8                            0                            0   \n",
       "9                            0                            0   \n",
       "\n",
       "   Income_Category_$80K - $120K  Income_Category_Less than $40K  \\\n",
       "3                             0                               1   \n",
       "4                             0                               0   \n",
       "5                             0                               1   \n",
       "8                             0                               1   \n",
       "9                             0                               1   \n",
       "\n",
       "   Card_Category_Blue  Card_Category_Gold  Card_Category_Platinum  \\\n",
       "3                   1                   0                       0   \n",
       "4                   1                   0                       0   \n",
       "5                   1                   0                       0   \n",
       "8                   1                   0                       0   \n",
       "9                   1                   0                       0   \n",
       "\n",
       "   Card_Category_Silver  \n",
       "3                     0  \n",
       "4                     0  \n",
       "5                     0  \n",
       "8                     0  \n",
       "9                     0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_dropped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8101, 38)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_missing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5690, 35)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_dropped_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Create Train_Test Split & Preprocess Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Create Train_Test_Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementation of future modeling, a train_test_split is created for both the missing and dropped datasets. The test size is arbritraily set for a 70/30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train_test_split for both missing and dropped bank churn datasets.\n",
    "#Test size arbritarily set at 70/30 split for training and future model performance and testing.\n",
    "\n",
    "X_missing = bank_missing_df.drop(['Attrition_Flag'], axis=1)\n",
    "y_missing = bank_missing_df['Attrition_Flag']\n",
    "X_dropped = bank_dropped_df.drop(['Attrition_Flag'], axis=1)\n",
    "y_dropped = bank_dropped_df['Attrition_Flag']\n",
    "\n",
    "\n",
    "X_train_missing, X_test_missing, y_train_missing, y_test_missing = train_test_split(X_missing, y_missing, test_size=0.30, random_state = random_number) \n",
    "X_train_dropped, X_test_dropped, y_train_dropped, y_test_dropped = train_test_split(X_dropped, y_dropped, test_size=0.30, random_state= random_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 Apply StandardScaler() for Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create equal distributions with mean centered at 0 between each of the features for future modeling, a standard scaler object is created and defined for training for both datasets. The same scaler is also applied for transforming X_test datasets for consistency and future modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created function for fitting and transforming scaler object for X_train of both datasets and then transform X_test for both datasets\n",
    "def scaling(train , test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train)\n",
    "    X_test_scaled = scaler.transform(test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_missing , X_test_scaled_missing = scaling(X_train_missing, X_test_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_dropped , X_test_scaled_dropped = scaling(X_train_dropped, X_test_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing as well the above arrays created after scaling the trained datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41349078,  1.28797953, -1.35293228, ..., -0.11017496,\n",
       "        -0.04408862, -0.24090084],\n",
       "       [ 1.45572316, -1.03949649,  0.0039595 , ..., -0.11017496,\n",
       "        -0.04408862, -0.24090084],\n",
       "       [ 0.33419479,  1.28797953, -0.85951709, ..., -0.11017496,\n",
       "        -0.04408862, -0.24090084],\n",
       "       ...,\n",
       "       [ 0.08496627,  2.06380487,  0.6207285 , ..., -0.11017496,\n",
       "        -0.04408862, -0.24090084],\n",
       "       [ 0.08496627,  0.51215419,  0.8674361 , ..., -0.11017496,\n",
       "        -0.04408862, -0.24090084],\n",
       "       [ 1.58033743, -1.03949649,  2.10097409, ..., -0.11017496,\n",
       "        -0.04408862, -0.24090084]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reviewing of X_train_scaled_missing and dropped as well as X_test_scaled_missing and dropped\n",
    "X_train_scaled_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33110890e+00, -2.63671151e-01,  3.95950466e-03, ...,\n",
       "        -1.10174961e-01, -4.40886190e-02, -2.40900841e-01],\n",
       "       [-4.13490784e-01,  1.28797953e+00, -2.42748093e-01, ...,\n",
       "        -1.10174961e-01, -4.40886190e-02, -2.40900841e-01],\n",
       "       [-1.90886194e+00, -1.03949649e+00, -1.72299368e+00, ...,\n",
       "        -1.10174961e-01, -4.40886190e-02, -2.40900841e-01],\n",
       "       ...,\n",
       "       [-2.88876521e-01, -1.03949649e+00, -2.42748093e-01, ...,\n",
       "        -1.10174961e-01, -4.40886190e-02,  4.15108555e+00],\n",
       "       [ 2.09580531e-01,  5.12154188e-01, -7.36163289e-01, ...,\n",
       "        -1.10174961e-01, -4.40886190e-02, -2.40900841e-01],\n",
       "       [ 3.34194794e-01,  1.28797953e+00,  8.67436097e-01, ...,\n",
       "        -1.10174961e-01, -4.40886190e-02, -2.40900841e-01]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.50889427,  0.52736863, -0.98537568, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       [-0.63893519, -1.02914063, -0.48336093, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       [ 0.35530376,  2.08387789, -0.10684986, ...,  9.5722467 ,\n",
       "        -0.03884166, -0.23532724],\n",
       "       ...,\n",
       "       [ 1.47382257,  1.30562326,  2.15221653, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       [ 1.22526283, -1.02914063,  1.02268333, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       [-1.50889427, -0.250886  , -2.86793101, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13605466,  1.30562326,  0.01865382, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       [ 0.35530376,  1.30562326,  0.01865382, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       [ 0.85242323,  0.52736863,  1.3991944 , ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       ...,\n",
       "       [-0.88749493, -0.250886  , -0.60886462, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       [-0.26609559,  1.30562326, -0.73436831, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724],\n",
       "       [-1.26033453,  0.52736863,  0.01865382, ..., -0.10446868,\n",
       "        -0.03884166, -0.23532724]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that arrays have been created for X_train, X_test, y_train, and y_test for each missing and dropped datasets, these will be utilized in the next steps regarding assessing model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled_missing shape: (5670, 37) and y_train_missing shape: (5670,)\n"
     ]
    }
   ],
   "source": [
    "#Missing X_train and y_train set shape\n",
    "print(f\"X_train_scaled_missing shape: {X_train_scaled_missing.shape} and y_train_missing shape: {y_train_missing.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_scaled_missing shape: (2431, 37) and y_test_missing shape: (2431,)\n"
     ]
    }
   ],
   "source": [
    "#Missing X_test and y_test set shape\n",
    "print(f\"X_test_scaled_missing shape: {X_test_scaled_missing.shape} and y_test_missing shape: {y_test_missing.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled_dropped shape: (3983, 34) and y_train_dropped shape: (3983,)\n"
     ]
    }
   ],
   "source": [
    "#Dropped X_train and y_train set shape\n",
    "print(f\"X_train_scaled_dropped shape: {X_train_scaled_dropped.shape} and y_train_dropped shape: {y_train_dropped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_scaled_dropped shape: (1707, 34) and y_test_dropped shape: (1707,)\n"
     ]
    }
   ],
   "source": [
    "#Dropped X_test and y_test set shape\n",
    "print(f\"X_test_scaled_dropped shape: {X_test_scaled_dropped.shape} and y_test_dropped shape: {y_test_dropped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a new csv file\n",
    "datapath = 'C:/Users/tpooz/OneDrive/Desktop/Data_Science_BootCamp_2023/SpringBoard_Github/Bank-Churnrate/0_Datasets'\n",
    "bank_clean_drop_numeric.to_csv('C:/Users/tpooz/OneDrive/Desktop/Data_Science_BootCamp_2023/SpringBoard_Github/Bank-Churnrate/0_Datasets/bank_data_train_preprocessed_dropped.csv') \n",
    "bank_clean_numeric.to_csv('C:/Users/tpooz/OneDrive/Desktop/Data_Science_BootCamp_2023/SpringBoard_Github/Bank-Churnrate/0_Datasets/bank_data_train_preprocessed_missing.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a further analysis and \"cleaning\" of the dataset from dropping NA columns and transforming non-numeric columns to numeric, feature values that have a moderate positive correlation with the target Attrition_Flag column are namely Total_Trans_Ct, Total_Ct_Chng_Q4_Q1, Total_Revolving_Bal, Avg_Utilization_Ratio, Total_Trans_Amt, Total_Relationship_Count, and Total_Amt_Chng_Q4_Q1 columns. And feature values with moderate negative correlation with Attrition_Flag column are namely Contacts_Count_12_mon and Months_Inactive_12_mon. Again there seems to be an intuitive sense to this, as based on the customers pattern of use, seems to correlate with whether or not the customer will attrite. Howevever, it seems that how many dependents a customer had or their relationship count, also had some affect on the variance for the Attrition_Flag column. These features will be kept in mind when in development of future steps for an appropraite predictive model. \n",
    "\n",
    "The above relationships were seen for both the datasets where the NA values were dropped vs. being imputed with 'missing' which means dropping the NA values in the columns did not seem to affect the overall correlation levels.\n",
    "\n",
    "Viewing the datasets and target variable, this will be a classification learning problem so different classification models (Logistic Regression, Random Forest, Gradeint Booosting, etc.) will be cross-validated and assessed to determine an appropriate model for prediction.\n",
    "\n",
    "Both datasets for values where the 'NA' values were dropped vs. NA values being imputed with missing were saved in order to be further analyzed and used to assess performance of next steps in developing a generalizable predictive model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
